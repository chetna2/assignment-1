{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db4600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2ddba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b6fefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56b7a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',skiprows = 1, header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04fae3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',  'marital_status', 'occupation','relationship', 'race', 'sex', 'capital_gain',  'capital_loss', 'hours_per_week', 'native_country', 'wage_class'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45bd71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.columns = col_labels \n",
    "test_set.columns = col_labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "daa24a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      wage_class  \n",
       "0          <=50K  \n",
       "1          <=50K  \n",
       "2          <=50K  \n",
       "3          <=50K  \n",
       "4          <=50K  \n",
       "...          ...  \n",
       "32556      <=50K  \n",
       "32557       >50K  \n",
       "32558      <=50K  \n",
       "32559      <=50K  \n",
       "32560       >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a7abe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6682b5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>32561</td>\n",
       "      <td>9</td>\n",
       "      <td>Private</td>\n",
       "      <td>22696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189778.366512</td>\n",
       "      <td>105549.977697</td>\n",
       "      <td>12285.0</td>\n",
       "      <td>117827.0</td>\n",
       "      <td>178356.0</td>\n",
       "      <td>237051.0</td>\n",
       "      <td>1484705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>32561</td>\n",
       "      <td>16</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>10501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>2.57272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>32561</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>14976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>32561</td>\n",
       "      <td>15</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>4140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>32561</td>\n",
       "      <td>6</td>\n",
       "      <td>Husband</td>\n",
       "      <td>13193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>32561</td>\n",
       "      <td>5</td>\n",
       "      <td>White</td>\n",
       "      <td>27816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>32561</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.30383</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_country</th>\n",
       "      <td>32561</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>29170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage_class</th>\n",
       "      <td>32561</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>24720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count unique                  top   freq           mean  \\\n",
       "age             32561.0    NaN                  NaN    NaN      38.581647   \n",
       "workclass         32561      9              Private  22696            NaN   \n",
       "fnlwgt          32561.0    NaN                  NaN    NaN  189778.366512   \n",
       "education         32561     16              HS-grad  10501            NaN   \n",
       "education_num   32561.0    NaN                  NaN    NaN      10.080679   \n",
       "marital_status    32561      7   Married-civ-spouse  14976            NaN   \n",
       "occupation        32561     15       Prof-specialty   4140            NaN   \n",
       "relationship      32561      6              Husband  13193            NaN   \n",
       "race              32561      5                White  27816            NaN   \n",
       "sex               32561      2                 Male  21790            NaN   \n",
       "capital_gain    32561.0    NaN                  NaN    NaN    1077.648844   \n",
       "capital_loss    32561.0    NaN                  NaN    NaN       87.30383   \n",
       "hours_per_week  32561.0    NaN                  NaN    NaN      40.437456   \n",
       "native_country    32561     42        United-States  29170            NaN   \n",
       "wage_class        32561      2                <=50K  24720            NaN   \n",
       "\n",
       "                          std      min       25%       50%       75%  \\\n",
       "age                 13.640433     17.0      28.0      37.0      48.0   \n",
       "workclass                 NaN      NaN       NaN       NaN       NaN   \n",
       "fnlwgt          105549.977697  12285.0  117827.0  178356.0  237051.0   \n",
       "education                 NaN      NaN       NaN       NaN       NaN   \n",
       "education_num         2.57272      1.0       9.0      10.0      12.0   \n",
       "marital_status            NaN      NaN       NaN       NaN       NaN   \n",
       "occupation                NaN      NaN       NaN       NaN       NaN   \n",
       "relationship              NaN      NaN       NaN       NaN       NaN   \n",
       "race                      NaN      NaN       NaN       NaN       NaN   \n",
       "sex                       NaN      NaN       NaN       NaN       NaN   \n",
       "capital_gain      7385.292085      0.0       0.0       0.0       0.0   \n",
       "capital_loss       402.960219      0.0       0.0       0.0       0.0   \n",
       "hours_per_week      12.347429      1.0      40.0      40.0      45.0   \n",
       "native_country            NaN      NaN       NaN       NaN       NaN   \n",
       "wage_class                NaN      NaN       NaN       NaN       NaN   \n",
       "\n",
       "                      max  \n",
       "age                  90.0  \n",
       "workclass             NaN  \n",
       "fnlwgt          1484705.0  \n",
       "education             NaN  \n",
       "education_num        16.0  \n",
       "marital_status        NaN  \n",
       "occupation            NaN  \n",
       "relationship          NaN  \n",
       "race                  NaN  \n",
       "sex                   NaN  \n",
       "capital_gain      99999.0  \n",
       "capital_loss       4356.0  \n",
       "hours_per_week       99.0  \n",
       "native_country        NaN  \n",
       "wage_class            NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38fe10d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e583f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5613b4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education_num     0\n",
       "marital_status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital_gain      0\n",
       "capital_loss      0\n",
       "hours_per_week    0\n",
       "native_country    0\n",
       "wage_class        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "311c1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  wage_class      32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7ac32",
   "metadata": {},
   "source": [
    "There are 32561 samples in the training dataset\n",
    "There are both categorical and numerical columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69c711b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16281 entries, 0 to 16280\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             16281 non-null  int64 \n",
      " 1   workclass       16281 non-null  object\n",
      " 2   fnlwgt          16281 non-null  int64 \n",
      " 3   education       16281 non-null  object\n",
      " 4   education_num   16281 non-null  int64 \n",
      " 5   marital_status  16281 non-null  object\n",
      " 6   occupation      16281 non-null  object\n",
      " 7   relationship    16281 non-null  object\n",
      " 8   race            16281 non-null  object\n",
      " 9   sex             16281 non-null  object\n",
      " 10  capital_gain    16281 non-null  int64 \n",
      " 11  capital_loss    16281 non-null  int64 \n",
      " 12  hours_per_week  16281 non-null  int64 \n",
      " 13  native_country  16281 non-null  object\n",
      " 14  wage_class      16281 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de8ebb",
   "metadata": {},
   "source": [
    "There are 16281 samples\n",
    "There are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2971eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hence there is no null data/ no missing values\n",
    "# replacing missing values with mean\n",
    "#df.albumin_and_globulin_ratio.fillna(df.albumin_and_globulin_ratio.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc391c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n",
      "       'hours_per_week'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_attributes = train_set.select_dtypes(include=['number'])\n",
    "print(num_attributes.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2740d767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'fnlwgt'}>],\n",
       "       [<AxesSubplot:title={'center':'education_num'}>,\n",
       "        <AxesSubplot:title={'center':'capital_gain'}>],\n",
       "       [<AxesSubplot:title={'center':'capital_loss'}>,\n",
       "        <AxesSubplot:title={'center':'hours_per_week'}>]], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_attributes.hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e5ed9",
   "metadata": {},
   "source": [
    "None of the numerical attributes have missing values\n",
    "The values are on different scales.  StandardScaler from the sklearn library to scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96154b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['workclass', 'education', 'marital_status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native_country', 'wage_class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_attributes = train_set.select_dtypes(include=['object'])\n",
    "print(cat_attributes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cbebd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count', ylabel='workclass'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y='workclass', hue='wage_class', data = cat_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b184f51",
   "metadata": {},
   "source": [
    "EDA!!! We are exploring different relations between data and how they interact... so do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d83afaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='count', ylabel='education'>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y='education', hue='wage_class', data = cat_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61a5104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# correlation between variables\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_set, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf809cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_set,hue='wage_class', kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e041d1",
   "metadata": {},
   "source": [
    "ALl the numerical columns have different metrics, using standard scaler, we convert it to same metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "71f10b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "916884fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03067056, -1.06361075,  1.13473876,  0.1484529 , -0.21665953,\n",
       "        -0.03542945],\n",
       "       [ 0.83710898, -1.008707  ,  1.13473876, -0.14592048, -0.21665953,\n",
       "        -2.22215312],\n",
       "       [-0.04264203,  0.2450785 , -0.42005962, -0.14592048, -0.21665953,\n",
       "        -0.03542945],\n",
       "       ...,\n",
       "       [ 1.42360965, -0.35877741, -0.42005962, -0.14592048, -0.21665953,\n",
       "        -0.03542945],\n",
       "       [-1.21564337,  0.11095988, -0.42005962, -0.14592048, -0.21665953,\n",
       "        -1.65522476],\n",
       "       [ 0.98373415,  0.92989258, -0.42005962,  1.88842434, -0.21665953,\n",
       "        -0.03542945]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object = StandardScaler()\n",
    "object.fit_transform(num_attributes ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e3a32ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week\n",
       "0       39   77516             13          2174             0              40\n",
       "1       50   83311             13             0             0              13\n",
       "2       38  215646              9             0             0              40\n",
       "3       53  234721              7             0             0              40\n",
       "4       28  338409             13             0             0              40\n",
       "...    ...     ...            ...           ...           ...             ...\n",
       "32556   27  257302             12             0             0              38\n",
       "32557   40  154374              9             0             0              40\n",
       "32558   58  151910              9             0             0              40\n",
       "32559   22  201490              9             0             0              20\n",
       "32560   52  287927              9         15024             0              40\n",
       "\n",
       "[32561 rows x 6 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c6a93f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      wage_class  \n",
       "0          <=50K  \n",
       "1          <=50K  \n",
       "2          <=50K  \n",
       "3          <=50K  \n",
       "4          <=50K  \n",
       "...          ...  \n",
       "32556      <=50K  \n",
       "32557       >50K  \n",
       "32558      <=50K  \n",
       "32559      <=50K  \n",
       "32560       >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4ad65fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <=50K   >50K\n",
       "0           1      0\n",
       "1           1      0\n",
       "2           1      0\n",
       "3           1      0\n",
       "4           1      0\n",
       "...       ...    ...\n",
       "32556       1      0\n",
       "32557       0      1\n",
       "32558       1      0\n",
       "32559       1      0\n",
       "32560       0      1\n",
       "\n",
       "[32561 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataDummies = pd.get_dummies(train_set['wage_class'])\n",
    "DataDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7015f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['Final'] = DataDummies.cumsum(axis=1).ne(1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8802d7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      wage_class  Final  \n",
       "0          <=50K      0  \n",
       "1          <=50K      0  \n",
       "2          <=50K      0  \n",
       "3          <=50K      0  \n",
       "4          <=50K      0  \n",
       "...          ...    ...  \n",
       "32556      <=50K      0  \n",
       "32557       >50K      1  \n",
       "32558      <=50K      0  \n",
       "32559      <=50K      0  \n",
       "32560       >50K      1  \n",
       "\n",
       "[32561 rows x 16 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea02be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K.</th>\n",
       "      <th>&gt;50K.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <=50K.   >50K.\n",
       "0            1       0\n",
       "1            1       0\n",
       "2            0       1\n",
       "3            0       1\n",
       "4            1       0\n",
       "...        ...     ...\n",
       "16276        1       0\n",
       "16277        1       0\n",
       "16278        1       0\n",
       "16279        1       0\n",
       "16280        0       1\n",
       "\n",
       "[16281 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataDummies = pd.get_dummies(test_set['wage_class'])\n",
    "DataDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed7140bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Final'] = DataDummies.cumsum(axis=1).ne(1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "10cd54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt      education  education_num  \\\n",
       "0       25        Private  226802           11th              7   \n",
       "1       38        Private   89814        HS-grad              9   \n",
       "2       28      Local-gov  336951     Assoc-acdm             12   \n",
       "3       44        Private  160323   Some-college             10   \n",
       "4       18              ?  103497   Some-college             10   \n",
       "...    ...            ...     ...            ...            ...   \n",
       "16276   39        Private  215419      Bachelors             13   \n",
       "16277   64              ?  321403        HS-grad              9   \n",
       "16278   38        Private  374983      Bachelors             13   \n",
       "16279   44        Private   83891      Bachelors             13   \n",
       "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
       "\n",
       "            marital_status          occupation     relationship  \\\n",
       "0            Never-married   Machine-op-inspct        Own-child   \n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital_gain  capital_loss  \\\n",
       "0                    Black     Male             0             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male          7688             0   \n",
       "4                    White   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours_per_week  native_country wage_class  Final  \n",
       "0                  40   United-States     <=50K.      0  \n",
       "1                  50   United-States     <=50K.      0  \n",
       "2                  40   United-States      >50K.      1  \n",
       "3                  40   United-States      >50K.      1  \n",
       "4                  30   United-States     <=50K.      0  \n",
       "...               ...             ...        ...    ...  \n",
       "16276              36   United-States     <=50K.      0  \n",
       "16277              40   United-States     <=50K.      0  \n",
       "16278              50   United-States     <=50K.      0  \n",
       "16279              40   United-States     <=50K.      0  \n",
       "16280              60   United-States      >50K.      1  \n",
       "\n",
       "[16281 rows x 16 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "69694375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0.234037\n",
       "fnlwgt           -0.009463\n",
       "education_num     0.335154\n",
       "capital_gain      0.223329\n",
       "capital_loss      0.150526\n",
       "hours_per_week    0.229689\n",
       "Final             1.000000\n",
       "Name: Final, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.corr()['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "725f364a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_33b3c_row0_col0,#T_33b3c_row1_col1,#T_33b3c_row2_col2,#T_33b3c_row3_col3,#T_33b3c_row4_col4,#T_33b3c_row5_col5,#T_33b3c_row6_col6{\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }#T_33b3c_row0_col1,#T_33b3c_row1_col0,#T_33b3c_row1_col2,#T_33b3c_row1_col5,#T_33b3c_row1_col6,#T_33b3c_row3_col4,#T_33b3c_row4_col3{\n",
       "            background-color:  #440154;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row0_col2{\n",
       "            background-color:  #481c6e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row0_col3,#T_33b3c_row2_col4,#T_33b3c_row5_col3{\n",
       "            background-color:  #482677;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row0_col4{\n",
       "            background-color:  #482071;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row0_col5,#T_33b3c_row5_col4{\n",
       "            background-color:  #481f70;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row0_col6{\n",
       "            background-color:  #3c4f8a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row1_col3,#T_33b3c_row2_col1{\n",
       "            background-color:  #460b5e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row1_col4{\n",
       "            background-color:  #46085c;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row2_col0{\n",
       "            background-color:  #482576;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row2_col3{\n",
       "            background-color:  #463480;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row2_col5{\n",
       "            background-color:  #453882;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row2_col6{\n",
       "            background-color:  #306a8e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row3_col0{\n",
       "            background-color:  #46327e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row3_col1,#T_33b3c_row4_col5{\n",
       "            background-color:  #481b6d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row3_col2,#T_33b3c_row4_col6{\n",
       "            background-color:  #453781;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row3_col5{\n",
       "            background-color:  #482374;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row3_col6{\n",
       "            background-color:  #3d4d8a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row4_col0{\n",
       "            background-color:  #472c7a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row4_col1,#T_33b3c_row6_col1{\n",
       "            background-color:  #481769;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row4_col2{\n",
       "            background-color:  #472a7a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row5_col0{\n",
       "            background-color:  #472f7d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row5_col1{\n",
       "            background-color:  #481467;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row5_col2{\n",
       "            background-color:  #433e85;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row5_col6{\n",
       "            background-color:  #3d4e8a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row6_col0{\n",
       "            background-color:  #365c8d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row6_col2{\n",
       "            background-color:  #2e6f8e;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row6_col3{\n",
       "            background-color:  #3b518b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row6_col4{\n",
       "            background-color:  #433d84;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_33b3c_row6_col5{\n",
       "            background-color:  #3c508b;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_33b3c_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >age</th>        <th class=\"col_heading level0 col1\" >fnlwgt</th>        <th class=\"col_heading level0 col2\" >education_num</th>        <th class=\"col_heading level0 col3\" >capital_gain</th>        <th class=\"col_heading level0 col4\" >capital_loss</th>        <th class=\"col_heading level0 col5\" >hours_per_week</th>        <th class=\"col_heading level0 col6\" >Final</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_33b3c_level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "                        <td id=\"T_33b3c_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row0_col1\" class=\"data row0 col1\" >-0.076646</td>\n",
       "                        <td id=\"T_33b3c_row0_col2\" class=\"data row0 col2\" >0.036527</td>\n",
       "                        <td id=\"T_33b3c_row0_col3\" class=\"data row0 col3\" >0.077674</td>\n",
       "                        <td id=\"T_33b3c_row0_col4\" class=\"data row0 col4\" >0.057775</td>\n",
       "                        <td id=\"T_33b3c_row0_col5\" class=\"data row0 col5\" >0.068756</td>\n",
       "                        <td id=\"T_33b3c_row0_col6\" class=\"data row0 col6\" >0.234037</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row1\" class=\"row_heading level0 row1\" >fnlwgt</th>\n",
       "                        <td id=\"T_33b3c_row1_col0\" class=\"data row1 col0\" >-0.076646</td>\n",
       "                        <td id=\"T_33b3c_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row1_col2\" class=\"data row1 col2\" >-0.043195</td>\n",
       "                        <td id=\"T_33b3c_row1_col3\" class=\"data row1 col3\" >0.000432</td>\n",
       "                        <td id=\"T_33b3c_row1_col4\" class=\"data row1 col4\" >-0.010252</td>\n",
       "                        <td id=\"T_33b3c_row1_col5\" class=\"data row1 col5\" >-0.018768</td>\n",
       "                        <td id=\"T_33b3c_row1_col6\" class=\"data row1 col6\" >-0.009463</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row2\" class=\"row_heading level0 row2\" >education_num</th>\n",
       "                        <td id=\"T_33b3c_row2_col0\" class=\"data row2 col0\" >0.036527</td>\n",
       "                        <td id=\"T_33b3c_row2_col1\" class=\"data row2 col1\" >-0.043195</td>\n",
       "                        <td id=\"T_33b3c_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row2_col3\" class=\"data row2 col3\" >0.122630</td>\n",
       "                        <td id=\"T_33b3c_row2_col4\" class=\"data row2 col4\" >0.079923</td>\n",
       "                        <td id=\"T_33b3c_row2_col5\" class=\"data row2 col5\" >0.148123</td>\n",
       "                        <td id=\"T_33b3c_row2_col6\" class=\"data row2 col6\" >0.335154</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row3\" class=\"row_heading level0 row3\" >capital_gain</th>\n",
       "                        <td id=\"T_33b3c_row3_col0\" class=\"data row3 col0\" >0.077674</td>\n",
       "                        <td id=\"T_33b3c_row3_col1\" class=\"data row3 col1\" >0.000432</td>\n",
       "                        <td id=\"T_33b3c_row3_col2\" class=\"data row3 col2\" >0.122630</td>\n",
       "                        <td id=\"T_33b3c_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row3_col4\" class=\"data row3 col4\" >-0.031615</td>\n",
       "                        <td id=\"T_33b3c_row3_col5\" class=\"data row3 col5\" >0.078409</td>\n",
       "                        <td id=\"T_33b3c_row3_col6\" class=\"data row3 col6\" >0.223329</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row4\" class=\"row_heading level0 row4\" >capital_loss</th>\n",
       "                        <td id=\"T_33b3c_row4_col0\" class=\"data row4 col0\" >0.057775</td>\n",
       "                        <td id=\"T_33b3c_row4_col1\" class=\"data row4 col1\" >-0.010252</td>\n",
       "                        <td id=\"T_33b3c_row4_col2\" class=\"data row4 col2\" >0.079923</td>\n",
       "                        <td id=\"T_33b3c_row4_col3\" class=\"data row4 col3\" >-0.031615</td>\n",
       "                        <td id=\"T_33b3c_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row4_col5\" class=\"data row4 col5\" >0.054256</td>\n",
       "                        <td id=\"T_33b3c_row4_col6\" class=\"data row4 col6\" >0.150526</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row5\" class=\"row_heading level0 row5\" >hours_per_week</th>\n",
       "                        <td id=\"T_33b3c_row5_col0\" class=\"data row5 col0\" >0.068756</td>\n",
       "                        <td id=\"T_33b3c_row5_col1\" class=\"data row5 col1\" >-0.018768</td>\n",
       "                        <td id=\"T_33b3c_row5_col2\" class=\"data row5 col2\" >0.148123</td>\n",
       "                        <td id=\"T_33b3c_row5_col3\" class=\"data row5 col3\" >0.078409</td>\n",
       "                        <td id=\"T_33b3c_row5_col4\" class=\"data row5 col4\" >0.054256</td>\n",
       "                        <td id=\"T_33b3c_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_33b3c_row5_col6\" class=\"data row5 col6\" >0.229689</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_33b3c_level0_row6\" class=\"row_heading level0 row6\" >Final</th>\n",
       "                        <td id=\"T_33b3c_row6_col0\" class=\"data row6 col0\" >0.234037</td>\n",
       "                        <td id=\"T_33b3c_row6_col1\" class=\"data row6 col1\" >-0.009463</td>\n",
       "                        <td id=\"T_33b3c_row6_col2\" class=\"data row6 col2\" >0.335154</td>\n",
       "                        <td id=\"T_33b3c_row6_col3\" class=\"data row6 col3\" >0.223329</td>\n",
       "                        <td id=\"T_33b3c_row6_col4\" class=\"data row6 col4\" >0.150526</td>\n",
       "                        <td id=\"T_33b3c_row6_col5\" class=\"data row6 col5\" >0.229689</td>\n",
       "                        <td id=\"T_33b3c_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x136cba93b50>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full correlation table\n",
    "train_set.corr().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b44a18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corelation is less, so lets proceed fruther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f39c129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm needs all data in numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b0aaaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['education'],_ = pd.factorize(train_set['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fe28c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c2525c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['workclass'],_ = pd.factorize(train_set['workclass'])\n",
    "train_set['marital_status'],_ = pd.factorize(train_set['marital_status'])\n",
    "train_set['occupation'],_ = pd.factorize(train_set['occupation'])\n",
    "train_set['relationship'],_ = pd.factorize(train_set['relationship'])\n",
    "train_set['race'],_ = pd.factorize(train_set['race'])\n",
    "train_set['sex'],_ = pd.factorize(train_set['sex'])\n",
    "train_set['native_country'],_ = pd.factorize(train_set['native_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4784aa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>77516</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>83311</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>215646</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>338409</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>257302</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>154374</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>151910</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>201490</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>287927</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0       39          0   77516          0             13               0   \n",
       "1       50          0   83311          0             13               1   \n",
       "2       38          1  215646          1              9               2   \n",
       "3       53          2  234721          2              7               1   \n",
       "4       28          0  338409          0             13               1   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "32556   27          6  257302          6             12               1   \n",
       "32557   40          1  154374          1              9               1   \n",
       "32558   58          1  151910          1              9               6   \n",
       "32559   22          1  201490          1              9               0   \n",
       "32560   52          1  287927          1              9               1   \n",
       "\n",
       "       occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0               0             0     0    0          2174             0   \n",
       "1               1             1     0    0             0             0   \n",
       "2               2             0     0    0             0             0   \n",
       "3               2             1     1    0             0             0   \n",
       "4               3             2     1    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "32556          10             2     0    1             0             0   \n",
       "32557           9             1     0    0             0             0   \n",
       "32558           0             4     0    1             0             0   \n",
       "32559           0             3     0    0             0             0   \n",
       "32560           1             2     0    1         15024             0   \n",
       "\n",
       "       hours_per_week  native_country wage_class  Final  \n",
       "0                  40               0      <=50K      0  \n",
       "1                  13               0      <=50K      0  \n",
       "2                  40               0      <=50K      0  \n",
       "3                  40               0      <=50K      0  \n",
       "4                  40               1      <=50K      0  \n",
       "...               ...             ...        ...    ...  \n",
       "32556              38               0      <=50K      0  \n",
       "32557              40               0       >50K      1  \n",
       "32558              40               0      <=50K      0  \n",
       "32559              20               0      <=50K      0  \n",
       "32560              40               0       >50K      1  \n",
       "\n",
       "[32561 rows x 16 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "16471ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['education'],_ = pd.factorize(test_set['education'])\n",
    "test_set['workclass'],_ = pd.factorize(test_set['workclass'])\n",
    "test_set['marital_status'],_ = pd.factorize(test_set['marital_status'])\n",
    "test_set['occupation'],_ = pd.factorize(test_set['occupation'])\n",
    "test_set['relationship'],_ = pd.factorize(test_set['relationship'])\n",
    "test_set['race'],_ = pd.factorize(test_set['race'])\n",
    "test_set['sex'],_ = pd.factorize(test_set['sex'])\n",
    "test_set['native_country'],_ = pd.factorize(test_set['native_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "42be8f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>226802</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>89814</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>336951</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>160323</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>103497</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>215419</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>321403</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>374983</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>83891</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>182148</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;50K.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0       25          0  226802          0              7               0   \n",
       "1       38          0   89814          1              9               1   \n",
       "2       28          1  336951          2             12               1   \n",
       "3       44          0  160323          3             10               1   \n",
       "4       18          2  103497          3             10               0   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "16276   39          0  215419          7             13               3   \n",
       "16277   64          2  321403          1              9               2   \n",
       "16278   38          0  374983          7             13               1   \n",
       "16279   44          0   83891          7             13               3   \n",
       "16280   35          6  182148          7             13               1   \n",
       "\n",
       "       occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0               0             0     0    0             0             0   \n",
       "1               1             1     1    0             0             0   \n",
       "2               2             1     1    0             0             0   \n",
       "3               0             1     0    0          7688             0   \n",
       "4               3             0     1    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "16276           5             2     1    1             0             0   \n",
       "16277           3             5     0    0             0             0   \n",
       "16278           5             1     1    0             0             0   \n",
       "16279           7             0     2    0          5455             0   \n",
       "16280           8             1     1    0             0             0   \n",
       "\n",
       "       hours_per_week  native_country wage_class  Final  \n",
       "0                  40               0     <=50K.      0  \n",
       "1                  50               0     <=50K.      0  \n",
       "2                  40               0      >50K.      1  \n",
       "3                  40               0      >50K.      1  \n",
       "4                  30               0     <=50K.      0  \n",
       "...               ...             ...        ...    ...  \n",
       "16276              36               0     <=50K.      0  \n",
       "16277              40               0     <=50K.      0  \n",
       "16278              50               0     <=50K.      0  \n",
       "16279              40               0     <=50K.      0  \n",
       "16280              60               0      >50K.      1  \n",
       "\n",
       "[16281 rows x 16 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6bb7576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_set.drop(['Final','wage_class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "93932e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>77516</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>83311</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>215646</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>338409</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>257302</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>154374</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>151910</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>201490</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>287927</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0       39          0   77516          0             13               0   \n",
       "1       50          0   83311          0             13               1   \n",
       "2       38          1  215646          1              9               2   \n",
       "3       53          2  234721          2              7               1   \n",
       "4       28          0  338409          0             13               1   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "32556   27          6  257302          6             12               1   \n",
       "32557   40          1  154374          1              9               1   \n",
       "32558   58          1  151910          1              9               6   \n",
       "32559   22          1  201490          1              9               0   \n",
       "32560   52          1  287927          1              9               1   \n",
       "\n",
       "       occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0               0             0     0    0          2174             0   \n",
       "1               1             1     0    0             0             0   \n",
       "2               2             0     0    0             0             0   \n",
       "3               2             1     1    0             0             0   \n",
       "4               3             2     1    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "32556          10             2     0    1             0             0   \n",
       "32557           9             1     0    0             0             0   \n",
       "32558           0             4     0    1             0             0   \n",
       "32559           0             3     0    0             0             0   \n",
       "32560           1             2     0    1         15024             0   \n",
       "\n",
       "       hours_per_week  native_country  \n",
       "0                  40               0  \n",
       "1                  13               0  \n",
       "2                  40               0  \n",
       "3                  40               0  \n",
       "4                  40               1  \n",
       "...               ...             ...  \n",
       "32556              38               0  \n",
       "32557              40               0  \n",
       "32558              40               0  \n",
       "32559              20               0  \n",
       "32560              40               0  \n",
       "\n",
       "[32561 rows x 14 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1de0c15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59dd0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_set.Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b66377f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32556    0\n",
       "32557    1\n",
       "32558    0\n",
       "32559    0\n",
       "32560    1\n",
       "Name: Final, Length: 32561, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "11fd8cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ba3f0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_set.drop(['Final','wage_class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "62404114",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_set.Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2748596d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "16276    0\n",
       "16277    0\n",
       "16278    0\n",
       "16279    0\n",
       "16280    1\n",
       "Name: Final, Length: 16281, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d75c0f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train values shape: (32561, 14)\n",
      "Test values shape: (16281, 14)\n",
      "Train target shape: (32561,)\n",
      "Test target shape: (16281,)\n"
     ]
    }
   ],
   "source": [
    "print('Train values shape:', X_train.shape)\n",
    "print('Test values shape:', X_test.shape)\n",
    "print('Train target shape:', y_train.shape)\n",
    "print('Test target shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2729f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\chetna\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\chetna\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost    # install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "75135bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "53d36558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e343823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=123,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7b72d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1e7a1f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "403f8f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32556    0\n",
       "32557    1\n",
       "32558    0\n",
       "32559    0\n",
       "32560    1\n",
       "Name: Final, Length: 32561, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "88c1c589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "49cf5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9b2ab98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=123,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     24720\n",
      "           1       0.84      0.72      0.78      7841\n",
      "\n",
      "    accuracy                           0.90     32561\n",
      "   macro avg       0.88      0.84      0.86     32561\n",
      "weighted avg       0.90      0.90      0.90     32561\n",
      "\n",
      "Test performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     12435\n",
      "           1       0.77      0.47      0.58      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.81      0.71      0.74     16281\n",
      "weighted avg       0.83      0.84      0.83     16281\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.7135133897515129\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[11880   555]\n",
      " [ 2032  1814]]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print('Test performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_test, y_test_pred))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "aced43ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406117560346416"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_predicted_values = best_model.predict(X_test)\n",
    "#accuracy_score(best_predicted_values, Y_test.values)\n",
    "accuracy_score(best_predicted_values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e5caec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 2587\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# use the model to make predictions with the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b594de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "24a1a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XGBOOSTadult_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "facfc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fedc73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1, random_state=123)\n",
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     24720\n",
      "           1       1.00      1.00      1.00      7841\n",
      "\n",
      "    accuracy                           1.00     32561\n",
      "   macro avg       1.00      1.00      1.00     32561\n",
      "weighted avg       1.00      1.00      1.00     32561\n",
      "\n",
      "Test performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     12435\n",
      "           1       0.78      0.42      0.54      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.81      0.69      0.72     16281\n",
      "weighted avg       0.83      0.83      0.81     16281\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.6892025427699859\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[11977   458]\n",
      " [ 2249  1597]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "model = RandomForestClassifier(n_jobs=-1,random_state=123)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "print(model)\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_hat))\n",
    "\n",
    "print('Test performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_test_hat))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_test, y_test_hat))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b0a2ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics, model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215ab94",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bf9d4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "\n",
    "'objective': 'binary:logistic',\n",
    "\n",
    "'max_depth': 2,\n",
    "\n",
    "'learning_rate': 1.0,\n",
    "\n",
    "'silent': 1.0,\n",
    "\n",
    "'n_estimators': 5\n",
    "\n",
    "}\n",
    "\n",
    "model = XGBClassifier(**params).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e522e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 2595\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# use the model to make predictions with the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9fddaa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406117560346416"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_predicted_values = best_model.predict(X_test)\n",
    "#accuracy_score(best_predicted_values, Y_test.values)\n",
    "accuracy_score(best_predicted_values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5e4a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalty specifies the norm in the penalization\n",
    "penalty = ['l1', 'l2']\n",
    "# C is the inverese of regularization parameter\n",
    "C = np.logspace(0, 4, 10)\n",
    "random_state=[0]\n",
    "# creating a dictionary of hyperparameters\n",
    "hyperparameters = dict(C=C, penalty=penalty, \n",
    "                  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b82b39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "a2afaa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Chetna\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Penalty: l1\n",
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(estimator = model, param_grid = hyperparameters, \n",
    "                   cv=5)\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params() ['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4dc62deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406117560346416"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_predicted_values = best_model.predict(X_test)\n",
    "#accuracy_score(best_predicted_values, Y_test.values)\n",
    "accuracy_score(best_predicted_values, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8897b6",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/michalbrezk/xgboost-classifier-and-hyperparameter-tuning-85\n",
    "https://towardsdatascience.com/logistic-regression-classifier-on-census-income-data-e1dbef0b5738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010ea49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e4840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
